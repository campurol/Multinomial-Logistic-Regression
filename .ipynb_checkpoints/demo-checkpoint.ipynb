{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License (MIT)\n",
    "\n",
    "Copyright (c) 2018 Lisong Guo <lisong.guo@me.com>\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "This notebook is intended to showcase how to use the MNL (Multinomial Logistic Regression) model to predict the booking probability for each option within a session.\n",
    "\n",
    "One can find the sample training and testing data under the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import the model and all the auxiliary functions\n",
    "from MNL import *\n",
    "from MNL_plus import *\n",
    "from Mint import *\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15,6\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 17\n",
      "========================\n",
      "{'loss': 'BinaryCrossEntropy', 'optimizer': 'Adam', 'learning_rate': 0.001, 'momentum': 0, 'weight_decay': 0, 'epochs': 20, 'early_stop_min_delta': 0.0001, 'patience': 5, 'gpu': True, 'verbose': 1, 'l1_loss_weight': 0, 'l2_loss_weight': 0, 'save_gradients': False, 'MNL_features': ['deptime_inbound_cos2p', 'deptime_inbound_cos4p', 'deptime_inbound_sin2p', 'deptime_inbound_sin4p', 'deptime_outbound_cos2p', 'deptime_outbound_cos4p', 'deptime_outbound_sin2p', 'deptime_outbound_sin4p', 'price_elasticity', 'reco_contains_CX', 'reco_contains_MH', 'reco_contains_OD', 'reco_contains_PG', 'reco_contains_SQ', 'reco_contains_TG', 'reco_contains_VN', 'rescaled_reco_eft']}\n",
      "========================\n",
      "epoch: 0  loss: 257.14750691641086 best_loss: 1000000000000000.0\n",
      "epoch: 1  loss: 181.9527746155091 best_loss: 257.14750691641086\n",
      "epoch: 2  loss: 179.82489137096906 best_loss: 181.9527746155091\n",
      "epoch: 3  loss: 178.99131734003572 best_loss: 179.82489137096906\n",
      "epoch: 4  loss: 178.5198961016953 best_loss: 178.99131734003572\n",
      "epoch: 5  loss: 178.2142450019986 best_loss: 178.5198961016953\n",
      "epoch: 6  loss: 177.99885687827924 best_loss: 178.2142450019986\n",
      "epoch: 7  loss: 177.83677491557432 best_loss: 177.99885687827924\n",
      "epoch: 8  loss: 177.7080036529151 best_loss: 177.83677491557432\n",
      "epoch: 9  loss: 177.6011383906259 best_loss: 177.7080036529151\n",
      "epoch: 10  loss: 177.50941785718138 best_loss: 177.6011383906259\n",
      "epoch: 11  loss: 177.42869012902756 best_loss: 177.50941785718138\n",
      "epoch: 12  loss: 177.35631606645237 best_loss: 177.42869012902756\n",
      "epoch: 13  loss: 177.29055846168347 best_loss: 177.35631606645237\n",
      "epoch: 14  loss: 177.23023191145148 best_loss: 177.29055846168347\n",
      "epoch: 15  loss: 177.17449695481238 best_loss: 177.23023191145148\n",
      "epoch: 16  loss: 177.12273628750592 best_loss: 177.17449695481238\n",
      "epoch: 17  loss: 177.07447884093074 best_loss: 177.12273628750592\n",
      "epoch: 18  loss: 177.02935237683914 best_loss: 177.07447884093074\n",
      "epoch: 19  loss: 176.9870533818987 best_loss: 177.02935237683914\n",
      "Final epoch: 19  loss: 176.9870533818987\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNkAAAIaCAYAAAAdhJvHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb27bfc0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "TRAIN_CONFIG = {\n",
    "    #'MNL_features': MNL_features,\n",
    "    \n",
    "    # when absent, by default, use all the features within the training data\n",
    "    #'MNL_features': MNL_features,\n",
    "    \n",
    "    # options: BinaryCrossEntropy, MaxLogLikelihood\n",
    "    #'loss':  'MaxLogLikelihood',\n",
    "    'loss':  'BinaryCrossEntropy',\n",
    "    \n",
    "    'optimizer': 'Adam',  # options:  Adam, RMSprop, SGD, LBFGS.\n",
    "    # Adam would converge much faster\n",
    "    # LBFGS is a very memory intensive optimizer (it requires additional param_bytes * (history_size + 1) bytes).\n",
    "    # If it doesn’t fit in memory try reducing the history size, or use a different algorithm.\n",
    "    # By default, history_size == 100\n",
    "    'learning_rate': 1e-3, # Applicable to Adam, SGD, and LBFGS\n",
    "    # The learning_rate parameter seems essential to LBFGS, which converges in two epochs.\n",
    "    #  So far, learning_rate == 0.1 seems to be ok for LBFGS\n",
    "    \n",
    "    #'momentum': 0.9,  # applicable to SGD, RMSprop\n",
    "    'momentum': 0,  # applicable to SGD, RMSprop\n",
    "    \n",
    "    # The resulting model seems to be more balanced, i.e. no extreme large/small weights,\n",
    "    #  although one might not have the most ideal performance, i.e. high top_5_rank etc.\n",
    "    'weight_decay': 0, # Applicable to Adam, RMSprop and SGD\n",
    "    \n",
    "    'epochs': 20,\n",
    "    'early_stop_min_delta': 1e-4,\n",
    "    'patience': 5,\n",
    "    \n",
    "    'gpu': True,  # luckily, running on GPU is faster than CPU in this case.\n",
    "    \n",
    "    # level of logging, 0: no log,  1: print epoch related logs;  2: print session related logs\n",
    "    'verbose': 1,\n",
    "    \n",
    "    # Adding the regularization degredates the performance of model\n",
    "    #   which might suggests that the model is still underfitting, not overfitting.\n",
    "    'l1_loss_weight': 0,  # e.g. 0.001 the regularization that would marginalize the weights\n",
    "    'l2_loss_weight': 0,\n",
    "    \n",
    "    # flag indicates whether to save gradients during the training\n",
    "    'save_gradients': False\n",
    "}\n",
    "\n",
    "\n",
    "# set random seed for reproduceability\n",
    "np.random.seed(17)\n",
    "torch.manual_seed(17)\n",
    "\n",
    "df_train = pd.read_csv('data/train_SINBKK_RT_B.csv')\n",
    "\n",
    "# Create a brand-new model\n",
    "model_tuple, loss_list = run_training(df_train, TRAIN_CONFIG)\n",
    "\n",
    "# Continue training on the existing model\n",
    "#model_tuple, loss_list = run_training(df_mlogit, TRAIN_CONFIG, model_tuple)\n",
    "\n",
    "\n",
    "# unzip the tuple\n",
    "(model, loss, optimizer) = model_tuple\n",
    "\n",
    "\n",
    "# plot the evolution of loss\n",
    "plot_loss(loss_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deptime_inbound_cos2p': -0.36398515004923043,\n",
       " 'deptime_inbound_cos4p': -0.26577859957974848,\n",
       " 'deptime_inbound_sin2p': -1.213463410585474,\n",
       " 'deptime_inbound_sin4p': -0.31855167737229889,\n",
       " 'deptime_outbound_cos2p': -0.93981497101512435,\n",
       " 'deptime_outbound_cos4p': -0.051423086136082735,\n",
       " 'deptime_outbound_sin2p': 0.25456406778561269,\n",
       " 'deptime_outbound_sin4p': -0.54952845899020164,\n",
       " 'price_elasticity': 0.0010554576044143206,\n",
       " 'reco_contains_CX': 0.89406695640341571,\n",
       " 'reco_contains_MH': -1.6215626453096521,\n",
       " 'reco_contains_OD': -0.90218537192269455,\n",
       " 'reco_contains_PG': -9.9075223796943561,\n",
       " 'reco_contains_SQ': 0.47816781886072446,\n",
       " 'reco_contains_TG': 0.20804998174678926,\n",
       " 'reco_contains_VN': -0.79540231827491503,\n",
       " 'rescaled_reco_eft': -0.96404073093394504}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "In this section, we test the trained model and calculate some performance benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of testing sessions: 542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>alter_id</th>\n",
       "      <th>choice</th>\n",
       "      <th>price_elasticity</th>\n",
       "      <th>rescaled_reco_eft</th>\n",
       "      <th>reco_contains_MH</th>\n",
       "      <th>reco_contains_TG</th>\n",
       "      <th>reco_contains_PG</th>\n",
       "      <th>reco_contains_SQ</th>\n",
       "      <th>reco_contains_VN</th>\n",
       "      <th>...</th>\n",
       "      <th>reco_contains_OD</th>\n",
       "      <th>deptime_outbound_sin2p</th>\n",
       "      <th>deptime_outbound_sin4p</th>\n",
       "      <th>deptime_outbound_cos2p</th>\n",
       "      <th>deptime_outbound_cos4p</th>\n",
       "      <th>deptime_inbound_sin2p</th>\n",
       "      <th>deptime_inbound_sin4p</th>\n",
       "      <th>deptime_inbound_cos2p</th>\n",
       "      <th>deptime_inbound_cos4p</th>\n",
       "      <th>pred_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>170326817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>248.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>-0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>-0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>0.144099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>170326817</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108867</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>-0.994056</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.025255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>170326817</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.854912</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>-0.518773</td>\n",
       "      <td>-0.461748</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.009953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>170326817</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>233.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>-0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.036251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>170326817</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>233.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108867</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>-0.994056</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>-0.461749</td>\n",
       "      <td>0.819152</td>\n",
       "      <td>-0.887011</td>\n",
       "      <td>0.573576</td>\n",
       "      <td>0.041227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  alter_id  choice  price_elasticity  rescaled_reco_eft  \\\n",
       "1617   170326817         0       1             248.6                0.0   \n",
       "1618   170326817         1       0             217.6                0.0   \n",
       "1619   170326817         2       0             217.6                0.0   \n",
       "1620   170326817         3       0             233.6                0.0   \n",
       "1621   170326817         4       0             233.6                0.0   \n",
       "\n",
       "      reco_contains_MH  reco_contains_TG  reco_contains_PG  reco_contains_SQ  \\\n",
       "1617                 0                 1                 0                 0   \n",
       "1618                 0                 1                 0                 0   \n",
       "1619                 0                 1                 0                 0   \n",
       "1620                 0                 1                 0                 0   \n",
       "1621                 0                 1                 0                 0   \n",
       "\n",
       "      reco_contains_VN     ...      reco_contains_OD  deptime_outbound_sin2p  \\\n",
       "1617                 0     ...                     0                0.906308   \n",
       "1618                 0     ...                     0               -0.108867   \n",
       "1619                 0     ...                     0               -0.854912   \n",
       "1620                 0     ...                     0                0.906308   \n",
       "1621                 0     ...                     0               -0.108867   \n",
       "\n",
       "      deptime_outbound_sin4p  deptime_outbound_cos2p  deptime_outbound_cos4p  \\\n",
       "1617               -0.766044               -0.422618               -0.642788   \n",
       "1618                0.216439               -0.994056                0.976296   \n",
       "1619                0.887011               -0.518773               -0.461748   \n",
       "1620               -0.766044               -0.422618               -0.642788   \n",
       "1621                0.216439               -0.994056                0.976296   \n",
       "\n",
       "      deptime_inbound_sin2p  deptime_inbound_sin4p  deptime_inbound_cos2p  \\\n",
       "1617              -0.906308              -0.766044               0.422618   \n",
       "1618               0.195090              -0.382683              -0.980785   \n",
       "1619               0.195090              -0.382683              -0.980785   \n",
       "1620               0.195090              -0.382683              -0.980785   \n",
       "1621              -0.461749               0.819152              -0.887011   \n",
       "\n",
       "      deptime_inbound_cos4p  pred_value  \n",
       "1617              -0.642788    0.144099  \n",
       "1618               0.923880    0.025255  \n",
       "1619               0.923880    0.009953  \n",
       "1620               0.923880    0.036251  \n",
       "1621               0.573576    0.041227  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test_SINBKK_RT_B.csv')\n",
    "\n",
    "test_results = test_model(model, df_test, TRAIN_CONFIG)\n",
    "\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of testing sessions: 542\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_size</th>\n",
       "      <th>rank_of_chosen_one</th>\n",
       "      <th>prob_of_chosen_one</th>\n",
       "      <th>max_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1702036</td>\n",
       "      <td>36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.025779</td>\n",
       "      <td>0.133754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1704193</td>\n",
       "      <td>60</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.102809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17033132</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266916</td>\n",
       "      <td>0.266916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17041139</td>\n",
       "      <td>60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.074934</td>\n",
       "      <td>0.247137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17042962</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.093615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  session_size  rank_of_chosen_one  prob_of_chosen_one  max_prob\n",
       "0     1702036            36                15.0            0.025779  0.133754\n",
       "1     1704193            60                 9.0            0.033080  0.102809\n",
       "2    17033132            60                 1.0            0.266916  0.266916\n",
       "3    17041139            60                 5.0            0.074934  0.247137\n",
       "4    17042962            60                11.0            0.037114  0.093615"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model with the testing data\n",
    "# Calculate the probability and the trank of the chosen alternative\n",
    "test_stats = validate(model, df_test, TRAIN_CONFIG)\n",
    "\n",
    "test_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the testing results into a list of KPIs, such as:\n",
    "\n",
    "- *mean_probability*: the average probability of the predicted alternative among all sessions\n",
    "\n",
    "\n",
    "- *top_5_rank_quantile*: the percentile of sessions where the probability of the predicted alternative is among the top 5.\n",
    "\n",
    "\n",
    "- *AIC*: Akaike Information Criterion, which offers an estimate of the relative information lost when a given model is used to represent the process that generated the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AIC': 3144.4564680427138,\n",
       " 'log_likelihood': -1555.2282340213569,\n",
       " 'mean_log_likelihood': -2.8694247860172637,\n",
       " 'mean_probability': 0.097970350765488143,\n",
       " 'mean_probability_diff': -0.081118023405807912,\n",
       " 'mean_rank': 8.5129151291512919,\n",
       " 'mean_rank_ratio': 0.17820222487861498,\n",
       " 'mean_session_size': 54.702952029520297,\n",
       " 'median_probability': 0.06263184576785641,\n",
       " 'median_probability_diff': -0.08119854629309217,\n",
       " 'median_rank': 5.0,\n",
       " 'median_rank_ratio': 0.1,\n",
       " 'session_num': 542,\n",
       " 'top_10_rank_quantile': 72.693726937269375,\n",
       " 'top_1_rank_quantile': 17.343173431734318,\n",
       " 'top_5_rank_quantile': 51.660516605166052}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_KPIs(test_stats, len(TRAIN_CONFIG['MNL_features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment\n",
    "\n",
    "In this section, we show some examples on how to use the APIs to serialize the model and eventually deploy it in the production environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deptime_inbound_cos2p': -0.36398515004923043,\n",
       " 'deptime_inbound_cos4p': -0.26577859957974848,\n",
       " 'deptime_inbound_sin2p': -1.213463410585474,\n",
       " 'deptime_inbound_sin4p': -0.31855167737229889,\n",
       " 'deptime_outbound_cos2p': -0.93981497101512435,\n",
       " 'deptime_outbound_cos4p': -0.051423086136082735,\n",
       " 'deptime_outbound_sin2p': 0.25456406778561269,\n",
       " 'deptime_outbound_sin4p': -0.54952845899020164,\n",
       " 'price_elasticity': 0.0010554576044143206,\n",
       " 'reco_contains_CX': 0.89406695640341571,\n",
       " 'reco_contains_MH': -1.6215626453096521,\n",
       " 'reco_contains_OD': -0.90218537192269455,\n",
       " 'reco_contains_PG': -9.9075223796943561,\n",
       " 'reco_contains_SQ': 0.47816781886072446,\n",
       " 'reco_contains_TG': 0.20804998174678926,\n",
       " 'reco_contains_VN': -0.79540231827491503,\n",
       " 'rescaled_reco_eft': -0.96404073093394504}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer the trained model to a minimized model for later inference.\n",
    "\n",
    "model_to_deploy = Mint(TRAIN_CONFIG['MNL_features'], model.get_feature_weights())\n",
    "\n",
    "model_to_deploy.get_feature_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model to  model/mint_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Dump/Pickle the model object into a binary file.\n",
    "model_to_deploy.save('model/mint_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from  model/mint_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# instantialize a new model from the pickle file\n",
    "inference_model = load_model('model/mint_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deptime_inbound_cos2p</th>\n",
       "      <th>deptime_inbound_cos4p</th>\n",
       "      <th>deptime_inbound_sin2p</th>\n",
       "      <th>deptime_inbound_sin4p</th>\n",
       "      <th>deptime_outbound_cos2p</th>\n",
       "      <th>deptime_outbound_cos4p</th>\n",
       "      <th>deptime_outbound_sin2p</th>\n",
       "      <th>deptime_outbound_sin4p</th>\n",
       "      <th>price_elasticity</th>\n",
       "      <th>reco_contains_CX</th>\n",
       "      <th>reco_contains_MH</th>\n",
       "      <th>reco_contains_OD</th>\n",
       "      <th>reco_contains_PG</th>\n",
       "      <th>reco_contains_SQ</th>\n",
       "      <th>reco_contains_TG</th>\n",
       "      <th>reco_contains_VN</th>\n",
       "      <th>rescaled_reco_eft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>-0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>-0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>248.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.994056</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>-0.108867</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.518773</td>\n",
       "      <td>-0.461748</td>\n",
       "      <td>-0.854912</td>\n",
       "      <td>0.887011</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>-0.980785</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>0.195090</td>\n",
       "      <td>-0.382683</td>\n",
       "      <td>-0.422618</td>\n",
       "      <td>-0.642788</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>-0.766044</td>\n",
       "      <td>233.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>-0.887011</td>\n",
       "      <td>0.573576</td>\n",
       "      <td>-0.461749</td>\n",
       "      <td>0.819152</td>\n",
       "      <td>-0.994056</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>-0.108867</td>\n",
       "      <td>0.216439</td>\n",
       "      <td>233.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      deptime_inbound_cos2p  deptime_inbound_cos4p  deptime_inbound_sin2p  \\\n",
       "1617               0.422618              -0.642788              -0.906308   \n",
       "1618              -0.980785               0.923880               0.195090   \n",
       "1619              -0.980785               0.923880               0.195090   \n",
       "1620              -0.980785               0.923880               0.195090   \n",
       "1621              -0.887011               0.573576              -0.461749   \n",
       "\n",
       "      deptime_inbound_sin4p  deptime_outbound_cos2p  deptime_outbound_cos4p  \\\n",
       "1617              -0.766044               -0.422618               -0.642788   \n",
       "1618              -0.382683               -0.994056                0.976296   \n",
       "1619              -0.382683               -0.518773               -0.461748   \n",
       "1620              -0.382683               -0.422618               -0.642788   \n",
       "1621               0.819152               -0.994056                0.976296   \n",
       "\n",
       "      deptime_outbound_sin2p  deptime_outbound_sin4p  price_elasticity  \\\n",
       "1617                0.906308               -0.766044             248.6   \n",
       "1618               -0.108867                0.216439             217.6   \n",
       "1619               -0.854912                0.887011             217.6   \n",
       "1620                0.906308               -0.766044             233.6   \n",
       "1621               -0.108867                0.216439             233.6   \n",
       "\n",
       "      reco_contains_CX  reco_contains_MH  reco_contains_OD  reco_contains_PG  \\\n",
       "1617                 0                 0                 0                 0   \n",
       "1618                 0                 0                 0                 0   \n",
       "1619                 0                 0                 0                 0   \n",
       "1620                 0                 0                 0                 0   \n",
       "1621                 0                 0                 0                 0   \n",
       "\n",
       "      reco_contains_SQ  reco_contains_TG  reco_contains_VN  rescaled_reco_eft  \n",
       "1617                 0                 1                 0                0.0  \n",
       "1618                 0                 1                 0                0.0  \n",
       "1619                 0                 1                 0                0.0  \n",
       "1620                 0                 1                 0                0.0  \n",
       "1621                 0                 1                 0                0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a session for test\n",
    "sample_session = df_test[df_test['session_id'] == 170326817]\n",
    "test_X = sample_session[TRAIN_CONFIG['MNL_features']]\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.55111512e-17,  -1.38777878e-17,  -1.73472348e-18,\n",
       "        -1.38777878e-17,  -1.38777878e-17,  -2.77555756e-17,\n",
       "        -3.46944695e-18,  -1.38777878e-17,  -1.38777878e-17,\n",
       "        -3.46944695e-18,   1.73472348e-18,   2.77555756e-17,\n",
       "         0.00000000e+00,  -1.73472348e-18,  -3.46944695e-18,\n",
       "        -6.93889390e-18,  -5.55111512e-17,  -3.46944695e-18,\n",
       "        -1.38777878e-17,  -3.46944695e-18,   0.00000000e+00,\n",
       "        -1.03397577e-25,  -1.61558713e-27,  -3.78653235e-29,\n",
       "        -1.73472348e-18,  -1.73472348e-18,  -6.93889390e-18,\n",
       "        -6.93889390e-18,  -8.27180613e-25,  -6.46234854e-27,\n",
       "        -5.04870979e-29,  -3.38813179e-21,  -6.77626358e-21,\n",
       "        -6.77626358e-21,  -1.01643954e-20,  -3.38813179e-21,\n",
       "        -1.69406589e-21,  -6.77626358e-21,  -1.69406589e-21,\n",
       "        -1.01643954e-20,  -1.69406589e-21,  -6.77626358e-21,\n",
       "        -1.69406589e-21,  -6.77626358e-21,  -8.47032947e-22,\n",
       "        -3.38813179e-21,  -3.38813179e-21,  -8.47032947e-22,\n",
       "        -3.38813179e-21,  -3.38813179e-21,  -1.69406589e-21,\n",
       "        -6.77626358e-21,  -8.47032947e-22,  -3.38813179e-21,\n",
       "        -1.35525272e-20,  -6.77626358e-21,  -1.69406589e-21,\n",
       "        -8.47032947e-22,  -1.69406589e-21,  -8.47032947e-22])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the results given by the original model with Pytorch and\n",
    "#   the inference model without pytorch. \n",
    "\n",
    "# Note: there are some subtle differences which should be due to the fact\n",
    "#   that the precision provided by Pytorch and Pandas/Numpy libraries is different.\n",
    "inference_model.predict(test_X) - model.predict(test_X).reshape(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
